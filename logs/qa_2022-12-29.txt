[2022-12-29 15:22:47] - INFO: 成功导入BERT配置文件 /home/gqt/extraction/relation/BertWithPretrained/bert_base_uncased_english/config.json
[2022-12-29 15:22:47] - INFO:  ### 将当前配置打印到日志文件中 
[2022-12-29 15:22:47] - INFO: ### project_dir = /home/gqt/extraction/relation/BertWithPretrained
[2022-12-29 15:22:47] - INFO: ### dataset_dir = /home/gqt/extraction/relation/BertWithPretrained/data/SQuAD
[2022-12-29 15:22:47] - INFO: ### pretrained_model_dir = /home/gqt/extraction/relation/BertWithPretrained/bert_base_uncased_english
[2022-12-29 15:22:47] - INFO: ### vocab_path = /home/gqt/extraction/relation/BertWithPretrained/bert_base_uncased_english/vocab.txt
[2022-12-29 15:22:47] - INFO: ### device = cuda:0
[2022-12-29 15:22:47] - INFO: ### train_file_path = /home/gqt/extraction/relation/BertWithPretrained/data/SQuAD/train-v1.1.json
[2022-12-29 15:22:47] - INFO: ### test_file_path = /home/gqt/extraction/relation/BertWithPretrained/data/SQuAD/dev-v1.1.json
[2022-12-29 15:22:47] - INFO: ### model_save_dir = /home/gqt/extraction/relation/BertWithPretrained/cache
[2022-12-29 15:22:47] - INFO: ### logs_save_dir = /home/gqt/extraction/relation/BertWithPretrained/logs
[2022-12-29 15:22:47] - INFO: ### model_save_path = /home/gqt/extraction/relation/BertWithPretrained/cache/model.pt
[2022-12-29 15:22:47] - INFO: ### n_best_size = 10
[2022-12-29 15:22:47] - INFO: ### max_answer_len = 30
[2022-12-29 15:22:47] - INFO: ### is_sample_shuffle = True
[2022-12-29 15:22:47] - INFO: ### use_torch_multi_head = False
[2022-12-29 15:22:47] - INFO: ### batch_size = 12
[2022-12-29 15:22:47] - INFO: ### max_sen_len = 384
[2022-12-29 15:22:47] - INFO: ### max_query_len = 64
[2022-12-29 15:22:47] - INFO: ### learning_rate = 3.5e-05
[2022-12-29 15:22:47] - INFO: ### doc_stride = 128
[2022-12-29 15:22:47] - INFO: ### epochs = 2
[2022-12-29 15:22:47] - INFO: ### model_val_per_epoch = 1
[2022-12-29 15:22:47] - INFO: ### vocab_size = 30522
[2022-12-29 15:22:47] - INFO: ### hidden_size = 768
[2022-12-29 15:22:47] - INFO: ### num_hidden_layers = 12
[2022-12-29 15:22:47] - INFO: ### num_attention_heads = 12
[2022-12-29 15:22:47] - INFO: ### hidden_act = gelu
[2022-12-29 15:22:47] - INFO: ### intermediate_size = 3072
[2022-12-29 15:22:47] - INFO: ### pad_token_id = 0
[2022-12-29 15:22:47] - INFO: ### hidden_dropout_prob = 0.1
[2022-12-29 15:22:47] - INFO: ### attention_probs_dropout_prob = 0.1
[2022-12-29 15:22:47] - INFO: ### max_position_embeddings = 512
[2022-12-29 15:22:47] - INFO: ### type_vocab_size = 2
[2022-12-29 15:22:47] - INFO: ### initializer_range = 0.02
[2022-12-29 15:22:47] - INFO: ### gradient_checkpointing = False
[2022-12-29 15:22:47] - INFO: ### layer_norm_eps = 1e-12
[2022-12-29 15:22:47] - INFO: ### model_type = bert
[2022-12-29 15:22:47] - INFO: ### pooler_type = first_token_transform
